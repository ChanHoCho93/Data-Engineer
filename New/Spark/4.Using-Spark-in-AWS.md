#### Using Spark in AWS

>**Lesson Introduction**
>
>* Data Lakes in AWS
>  * Stuctured and Unstructured Data(Data Lakes에 포함할수 있는 데이터)
>  * AWS S3 Data Lakes(S3 버킷을 Data Lakes로 사용하여 Spark 작업에 대한 데이터를 저장)
>
>* Using Spark on AWS
>  * EC2 Instances(회사에서 EC2를 사용하여 Spark를 실행하는 방법)
>  * AWS EMR
>  * AWS Glue
>* AWS Glue
>  * Glue Service Components
>  * Spark Glue Jobs
>  * Creating and Running Glue Jobs
>* you will be able to
>  * Identify properties of Data Lakes
>  * Load data to an S3 Landing Zone
>  * Create and run Spark Jobs Using Glue Studio
>  * Create a Trusted Zone in S3 using Glue
>  * Read and Write to amazon S3 in a Glue Job

>**Data Lakes in AWS**
>
>* Data Lakes In the AWS Cloud
>  * Data Lakes는 특정 기술이 아니라 Stuctured and Unstructured Data의 모임이다.
>  * Data Lakes는 다양한 유형의 파일 저장 시스템을 사용하여 구현할 수 있다.
>  * AWS S3를 사용하여 데이터 레이크를 구현할 수 있다.
>* S3 Data Lakes and Spark on AWS
>  * Hadoop의 HDFS와 마찬가지로 AWS는 S3를 만들었다.
>  * S3 버킷은 HDFS와 유사한 스토리지의 추상화이다.
>  * S3의 최상위 수준을 S3 버킷 이라고 한다.
>  * S3는 스토리지 용량이 거의 제한되어 잇고 매우 저렴하기 떄문에 Data Lakes용 데이터를 저장하기에 이상적이다.
>  * RDS 및 EC2와 같이 다른 정교한 데이터 위치의 비용과 비교할때 S3는 훨씬 저렴하다.
>  * S3와 관련된 컴퓨팅 비용이 없으므로 많은 양의 파일을 저장할 장소가 필요할 경우 S3가 최적이다.

>**Using Spark on AWS**
>
>* Using Spark 
>  * EMR - EMR은 Spark를 실행하도록 구성 확장 가능한 EC2 AWS 관리형 Spark 서비스이다. 시스템을 관리하지 않고 필요한 클러스터 리소스만 구성한다.
>  * EC2 - EC2 시스템을 사용하고 Spark 및 HDFS를 직접 설치 및 구성한다.
>  * Glue - Glue Context 및 Glue 동적 프레임과 같은 라이브러리가 추가된 서비리스 Spark 환경이다. 다른 AWS 데이터 서비스와 인터페이스한다.
>
>* Differences btween Spark on AWS EC2 vs EMR
>
>  |                       | AWS EMR   | AWS Glue          | Self Managed Spark |
>  | --------------------- | --------- | ----------------- | ------------------ |
>  | Distributed Computing | Yes       | Yes               | Yes                |
>  | Serverless            | No        | Yes               | No                 |
>  | HDFS Installed        | Yes       | Yes               | Yes                |
>  | Billing Model         | EC2 costs | Job Duration      | EC2 costs          |
>  | Provisioning          | Automated | Zero Provisioning | Self Installed     |
>
>* HDFS and Spark
>  * Spark에는 자체 분산 스토리지 시스템이 없기 때문에 HDFS 또는 AWS S3는 기타 스토리지를 이용해야 한다.
>  * HDFS는 MapReudc System을 리소스 관리자로 사용하여 클러스터 내의 하드 드라이브에 파일을 배포할 수 있다.
>  * Spark는 작업을 실행하고 HDFS에서 사용하는 하드 드라이브가 아닌 RAM 메모리에 데이터를 보관한다.
>  * Spark에는 파일 배포 시스템이 없기때문에 HDFS를 사용할수 있는 Hadoop에 설치되는 경우가 많다.
>* Why Would you Use an EMR Cluster?
>  * Spark Cluster에는 여러 머신이 포함되어 있으므로 각 머신에서 Spark 코드를 사용하려면 Spark와 해당 종속 항목을 다운로드하여 설치하는 수동 프로세스 때문에 AWS EMR를 사용하면 이 수동 프로세스를 거칠필요가 없다.
>
>
>
>
>
>
