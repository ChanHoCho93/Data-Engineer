#### Spark Essentials

>**Introduction to Spark Essentials**
>
>* 필수 Spark 개념
>  * Spark directed acycilc graph ( DAG, 비순환 그래프)
>  * Resilient Distributed Datasets (RDD)
>* Spark의 Map, Rambda
>  * The Spark Context Object
>  * Spark가 lazy evaluation를 사용하여 코들르 실행하는 방법
>  * Spark 코드에서 anonymous lambda functions를 사용하는 방법
>* Spark의 data wrangling
>  * Spar DataFrames에서 데이터를 읽고 쓰는 방법
>  * 데이터 랭글링을 위한 일반 DataFrame 함수
>  * SQL로 데이터 프레임을 쿼리하는 방법
>  * DataFrames와 Spark SQL을 사용한 데이터 랭글링을 비교하는 예
>* be able to..
>  * Spark DAG가 데규모 데이터 세트의 병렬 처리를 가능하게 하는 방법 설명
>  * Map 및 Lambda Spark 함수 사용
>  * SparkSQL 및 Spark DataFrames로 데이터 조작
>
>https://pandas.pydata.org/

>**Spark DAG: Teamwork for Data Processing**
>
>* 나오는 개념
>  * idempotent (멱등)
>  * RDD
>  * DAG
>  * Lazy Evaluation
>
>1. 결과에 영향을 주지 않는 idempotent의 한가지 목표는 데이터를 병렬 또는 동시에 처리할 수 있다.
>2. idempotent의 개념을 가짐으로서 서로 다른 스레드 및 서로 다른 노드 또는 서버에서 동일한 코드를 반복적으로 호출하여 수행하며, 분할 처리에 문제가 없어야 한다.
>3. 코드에서 배열이나 리스트로 처리할때 양이 매우 만을수도 있으므로 코드로 데이터로 읽지 않는 것이 매우 중요하다. 그래서 데이터를 읽을때 RDD 및 DataFrames 라는 데이터세트를 사용한다.
>4. RDD 및 DataFrames는 SQL query cursor와 마찬가지로 모든 데이터를 메모리에 저장하지 않고 이러한 데이터 세트는 Spark 작업 외부에서 ㅈ관리도니느 매우 제어된 방식으로 클러스터 공유 리소스에 대한 Spark 작업 액세스를 제공한다.
>5. Spark는 입력 데이터의 복사본을 만들며 원래 부모 데이터를 변경하지 않고 입력 데이터를 변경하지 않기 때문에 immutable이라고 한다.
>6. Spark에서 DAG 개념이 들어가는데 Spark는 함수 호출이 많으면 각각 작업의 작은 부분을 수행하는 여러 함수를 호출을 함께 연결하여 작업을 수행한다.
>7. Spark DAG는 모든 단계가 순차적으로 코드에 나타날수 있고 Spark가 더 최적의 실행 계획을 찾으면 더 효율적으로 실행될 수 있다.
>
><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230620074547037.png" alt="image-20230620074547037" style="zoom:67%;" />

>**Resilient Distributed Datasets(RDD)**
>
>* RDD의 기능은 효율적인 데이터 처리를 위해 설계 되었다.
>
>* 소스 데이터는 데이터 베이스, CSV, JSON 또는 텍스트 파일에 로드되는데 Spark는 이 데이터를 RDD라는 분산 처리를 위한 불변 개체 컬렉션으로 변환한다.
>* RDD를 사용하면 유연성을 가지지만 코드를 작성하고 읽기가 더 어렵다.

>**PySpark and SparkSession**
>
>* RDDs
>* DataFrames
>* Spark SQL

>**Maps and Lambda Functions**
>
>* 데이터 파일을 SparkContext를 통해 클러스터 머신 전체에 배포하고 배포된 클러스터를 바탕으로 데이터 작업을 한다.
>
>* Lambda 사용 가능 

>**Imperative vs Declarative programming**
>
>* Julia에게 케잌을 사주자 할때의 예제
>
><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230621072528118.png" alt="image-20230621072528118" style="zoom: 67%;" />

>**Spark SQL**
>
>* Declarative 방식의 쿼리
>* Analysts 와 data scientists가 SQL 사용하는것을 선호
>* Spark는 SQL코드를 자동으로 최적화하여 데이터 조작  및 검색 프로세스 속도를 높힌다.
>* [Spark SQL built-in functions](https://spark.apache.org/docs/latest/api/sql/index.html)
>
>* [Spark SQL guide](https://spark.apache.org/docs/latest/sql-getting-started.html)
