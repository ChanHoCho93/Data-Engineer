#### Big Data Ecosystem, Data Lakes, and Spark

>![image-20230613072525532](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230613072525532.png)
>
>* Hadoop Distributed File System은 데이터에 대한 많은 처리가 가능한 분산 스토리지를 제공
>* MapReduce는 대량의 데이터에 대해 대규모 병렬 처리를 수행하는 방법을 제공
>* Spark는 Hadoop의 아이디어를 기반으로 구축되었으며 데이터 처리를 위한 여러 프로그래밍 API와 데이터 엔지니어링 및 데이터 과학 솔루션을 반복적으로 개발하기 위한 대화형 인터페이스를 제공
>* Lake house는 data lakes와 data warehouse의 강점을 결합

>**Lesson Outline**
>
>Lesson Objectives
>
>* Hadoop 프레임워크의 기술과 구성 요소를 식별할 수 있습니다.
>* Spark를 사용할때와 상용하지 않을 때를 식별할 수 있습니다.
>* 빅 데이터 샡애계에서 데이터 레이크의 특징과 진화를 설명할 수 있습니다.

>**Insight: From Hadoop to Data Lakehouse**
>
>![image-20230613074446486](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230613074446486.png)
>
>* Data warehouse는 구체적이고 명시적인 데이터 구조를 기반으로 하지만 구조화되지 않은 데이터에서는 제대로 수행되지 않습니다.
>* Data lakes는 Hadoop 및 Spark를 통해 대량의 정형 데이터와 비정형 데이터를 수집할 수 있으며 이러한 데이터 세트 위에서 처리를 제공합니다.
>* Data lakes에는 유연성에서 비롯된 몇 가지 단점이 있는데, 트랜잭션을 지원할 수 없으며 변화하는 데이터 세트가 제대로 수행되지 않습니다. 이러한 시스템의 구조화 되지 않은 특성으로 인해 Data governance가 어려워졌습니다.
>* 최신 Lakehouse architectures는 data warehouse와 data lakes의 강점을 하나의 강력한 아키텍처로 결합하려고 합니다.

>**The Hadoop Ecosystem**
>
>![image-20230614065651937](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230614065651937.png)
>
>* Hadoop
>  * 빅 데이터 저장 및 데이터 분석을 위한 도구, Ecosystem
>  * Spark와 Hadoop의 주요 차이점은 메모리를 사용하는 방식, Hadoop은 중간 결과를 디스크에 쓰는 반면 Spark는 가능할 때마다 데이터를 메모리에 유지하려고 함
>* Hadoop MapReduce - 대용량 데이터 세트를 병렬로 처리하고 분석하는 시스템
>* Hadoop YARN - 클러스터 전체에서 작업을 예약하는 리소스 관리자, 관리자는 사용 가능한 컴퓨터 리소스를 추적한 다음 해당 리소스를 특정 작업에 할당
>
>* Hadoop Distributed File System(HDFS) - 데이터를 Chunk로 분할하고 컴퓨터 클러스터 전체에 Chunk를 저장하는 빅 데이터 스토리지 시스템
>* Hadoop Tool
>  * Apache Pig - Hadoop MapReduce 위에서 실행되는 SQL 유사 언어
>  * Apache Hive - Hadoop MapReduce 위에서 실행되는 또 다른 SQL 유사 인터페이스
>
>* Spark는 Hadoop와 어떤 관련?
>  * Spark에는 데이터 분석, 기계 학습, 그래프 분석 및 라이브 데이터 스트리밍을 위한 라이브러리가 포함
>  * Spark는 일반적으로 Hadoop보다 빠름, Hadoop 은 중간 결과를 디스크에 쓰고, Spark는 가능할 때마다 중간 결과를 메모리에 유지 하려고 함
>  * Hadoop Ecosystem에는 HDFS가 포함되는 반면 Spark에는 파일 저장 시스템이 포함되어 있지 않음
>  * HDFS 위에 Spark를 사용할 수 있지만 그럴 필요 없음, Spark는 다른 소스에서도 데이터를 읽을 수 있음
>* Streaming Data
>  * Apache Strom
>  * Apache Flink

>**MapReduce** 
>
>![image-20230614071429741](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230614071429741.png)
>
>* HDFS에서 파일을 작은 Chunk로 분할
>
>![image-20230614071601109](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230614071601109.png)
>
>1. Map 단계에서 각 데이터를 튜플로 변환
>2. Shuffle 단계에서 모든 키가 동일한 시스템에 있도록 셔플
>3. Reduce 단계에서 동일한  키를 가진 값을 결합
>

>**The Spark Cluster**
>
><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230619074307909.png" alt="image-20230619074307909" style="zoom:50%;" />
>
>* 대부분의 분산 컴퓨팅 프레임 워크는 master-worker 계층 구조로 구성
>* master node는 클러스터 전체에서 작업 조정을 담당
>* worker node가 실제 계산을 수행
>* Spark의 4가지 mode
>  * local mode: 단일 시스템에서 발생
>  * spark's own Standalone Customer Manager: 드라이버 프로세스가 있고, Python 또는 Scala와 같은 Spark 셸을 열면 드라이버 프로그램과 직접 상호 작용, 마스터 역활을 하며 작업 예약을 담당
>  * Hadoop 의 YARN
>  * UC Berkeley의 AMPLab Coordinators의 또 다른 오픈 소스 관리자

>**Spark Use Cases: 반복 알고리즘에 유용(중간 데이터를 메모리에 씀)**
>
>* Data Analytics
>* Machine Learning
>* Streaming
>* Graph Analytics
>* Spark-Use-Cases.md 참고

>**Data Lakes**
>
><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230619090801054.png" alt="image-20230619090801054" style="zoom:50%;" />
>
>* Data Warehouses 안팎으로 구조화 되어야 한다.
>* Data Lake는 모든 데이터를 단일 리포지토리에 저장하여 필요한 사람과 장소에 구애받지 않고 사용할 수 있다.
>
>![image-20230619091023579](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230619091023579.png)
>
>* Data Warehouse와 Data Lake의 주요 차이점 중 하나는 정형 데이터와 비정형 데이터를 포함한다.
>* 데이터 웨어하우스는 비지니스 인텔리전스 및 보고 요구 사항에 적합한 고도로 구조화된 데이터로만 구성 된다.
>* Data Lake의 주요 기능
>   * ETL/ELT 작업을 위한 빅 데이터 도구 사용과 관련된 비용 절감.
>  * Data Lake는 많은 양의 데이터를 수집하는 작업과 비용을 낮추는 schema-on-write 가 아닌 schema-on-read를 제공 한다.
>  * Data Lake는 정형,반정형 및 비정형 데이터를 지원한다.

>**Data Lakes, Lakehouse, and Spark**
>
><img src="C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230619091711354.png" alt="image-20230619091711354" style="zoom:67%;" />

>**Data Lakehouse**
>
>* Data Warehouse -> Data Lake로 발전했지만 대량의 비정형 데이터를 수집해야 했기 때문에 단점이 생긴다.
>  * Atomic transactions: 실패한 프로덕션 작업으로 인해 데이터가 손상된 상태로 남음.
>  * Quality enforcement: 일관성이 없어 사용할 수 없는 데이터가 있음.
>  * Consistency in data structures: 수집하는 동안 데이터를 스트리밍하고 일괄 처리할 수 없음.
>
>![image-20230619092806242](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20230619092806242.png)
>
>* Lakehouse Architecture: 데이터 레이크위에 메타데이터 및 데이터 거버넌스 계층을 생성
>  * 이렇게 하면 원시 데이터 풀과 선별된 데이터 세트가 생성되어, 데이터 레이크의 약점에 대한 솔루션과 데이터 레이크의 유연성과 이점을 제공.
>
>* Lakehouse Architecture Features: 주요 기능은 대량의 데이터를 신속하게 수집한 다음 데이터의 품질을 점진적으로 개선하는 기능
>  * 수집한 원시 데이터
>  * 일부 필터링, 정리 및 보강
>  * 비지니스 수준 집계 처리후 분석 및 보고 요구 사항에 사용
>* Data Lake and Lakehouse Architecture 차이점
>  * 주요 차이점은 메타데이터와 거버넌스 계층이 포함되어 있다는 것이다. 이는 Data Lake에 원자성, 데이터 품질 및 일관성을 제공하는 중요한 요소이다.

>**Summary**
>
>- The big data ecosystem and the history of batch processing
>- Spark vs. Hadoop
>- Spark's typical use cases, and when you should, or shouldn't use Spark
>- Overview of data lakes and lakehouse architecture
